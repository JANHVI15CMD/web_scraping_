
#  Web Scraping Portfolio with Python

Welcome to my professional web scraping portfolio!  
This repository contains everything from learning notes to hands-on projects using Python's most powerful scraping tools:

- **Requests** for HTTP communication  
- **BeautifulSoup** for HTML parsing  
- **Selenium** for browser automation & dynamic content  
- Real-world projects with data saved into `.xlsx` files via `pandas + openpyxl`

---

##  Folder Structure

| Folder                 | Contents                                                                 |
|------------------------|--------------------------------------------------------------------------|
| `requests/`            | `Request.md`, sample scripts for GET/POST, headers, query params           |
| `beautiful_soup/`      | `Beautiful_soup.md`, HTML parsing examples, tag navigation, CSS selectors         |
| `selenium/`            | `Selenium`, browser automation scripts (login, scrolling, extraction)    |
| `projects/`            | Real-world scrapers with `.py` scripts and `.xlsx` outputs               |


---

##  Tools & Technologies

- Python 3.x  
- Requests  
- Beautiful Soup 4  
- Selenium WebDriver  
- Pandas + openpyxl  
- ChromeDriver (via Chocolatey)  
- Git & GitHub  

---

##  How to Use

```bash
# 1. Clone the repo
git clone https://github.com/your-username/Web_Scraping.git
cd Web_Scraping

# 2. Install dependencies
pip install -r requirements.txt

# 3. Run any script
python projects/project1_yahoo_finance.py
```

---
## Projects Included

### üìà Project 1: Yahoo Finance Scraper  
**URL:** [https://finance.yahoo.com/](https://finance.yahoo.com/)  
**Goal:** Extract market summaries, stock prices, news headlines.

---

### üè† Project 2: 99Acres Real Estate Scraper  
**URL:** [https://www.99acres.com/](https://www.99acres.com/)  
**Goal:** Scrape property listings‚Äîprice, location, area.

---

### üìù Project 3: QuotesToScrape Series

| Sub-project | URL | Description |
|-------------|-----|-------------|
| 3.1 | [https://quotes.toscrape.com/](https://quotes.toscrape.com/) | Data extraction with Selenium |
| 3.2 | [https://quotes.toscrape.com/scroll](https://quotes.toscrape.com/scroll) | Infinite scroll scraping with Selenium |
| 3.3 | [https://quotes.toscrape.com/login](https://quotes.toscrape.com/login) | Login automation |


##  Learning Topics Covered

- HTTP requests (GET/POST) with custom headers & params  
- HTML parsing using BeautifulSoup (`.find()`, `.select()`, XPath)  
- Browser automation with Selenium (login, clicks, scrolling, waits, etc)  
- Handling pagination, alerts, iframes, dynamic content  
- Exporting scraped data to Excel (`.xlsx`) using pandas  

---

##  About Me

Hi! I‚Äôm **[Janhvi Tiwari]**, an aspiring data automation developer.  
- üî≠ Currently building and sharing web scraping projects  
- üì´ Connect with me on [LinkedIn](https://www.linkedin.com/in/janhvi-tiwari-1bb152292/)  
- üíª Explore my other work: https://github.com/JANHVI15CMD 

---

##  Ethical Disclaimer

This project is for educational purposes only.  
Please respect each website‚Äôs `robots.txt` and Terms of Service.
