
#  Web Scraping Portfolio with Python

Welcome to my professional web scraping portfolio!  
This repository contains everything from learning notes to hands-on projects using Python's most powerful scraping tools:

- **Requests** for HTTP communication  
- **BeautifulSoup** for HTML parsing  
- **Selenium** for browser automation & dynamic content  
- Real-world projects with data saved into `.xlsx` files via `pandas + openpyxl`

---

##  Folder Structure

| Folder                 | Contents                                                                 |
|------------------------|--------------------------------------------------------------------------|
| `requests/`            | `Request.md`, sample scripts for GET/POST, headers, query params           |
| `beautiful_soup/`      | `Beautiful_soup.md`, HTML parsing examples, tag navigation, CSS selectors         |
| `selenium/`            | `Selenium`, browser automation scripts (login, scrolling, extraction)    |
| `projects/`            | Real-world scrapers with `.py` scripts and `.xlsx` outputs               |


---

##  Tools & Technologies

- Python 3.x  
- Requests  
- Beautiful Soup 4  
- Selenium WebDriver  
- Pandas + openpyxl  
- ChromeDriver (via Chocolatey)  
- Git & GitHub  

---

##  How to Use

```bash
# 1. Clone the repo
git clone https://github.com/your-username/Web_Scraping.git
cd Web_Scraping

# 2. Install dependencies
pip install -r requirements.txt

# 3. Run any script
python projects/project1_yahoo_finance.py
```

---

##  Projects Included

###  Project 1: Yahoo Finance Scraper
- **URL**: https://finance.yahoo.com/  
- **Goal**: Extract market summaries, stock prices, news headlines.  
- **Output**: Saved to `Project1\yahoo-stocks-data.xlsx`.

---

###  Project 2: 99Acres Real Estate Scraper
- **URL**: https://www.99acres.com/  
- **Goal**: Scrape property listingsâ€”price, location, area.  
- **Output**: Saved to `Project2\chennai-properties-99acres.xlsx`.

---

###  Project 3: QuotesToScrape Series

| Subâ€‘project | URL                                          | Description                                         | Output                    |
|-------------|----------------------------------------------|-----------------------------------------------------|---------------------------|
| **3.1**     | https://quotes.toscrape.com/                | Data extraction with Selenium.             | `Project3\scraped_quotes.xlsx`         |
| **3.2**     | https://quotes.toscrape.com/scroll          | Infinite scroll scraping with Selenium              | `Project3\scraped_quotes.xlsx`         |
| **3.3**     | https://quotes.toscrape.com/login           | Login automation   |      |

---

##  Learning Topics Covered

- HTTP requests (GET/POST) with custom headers & params  
- HTML parsing using BeautifulSoup (`.find()`, `.select()`, XPath)  
- Browser automation with Selenium (login, clicks, scrolling, waits, etc)  
- Handling pagination, alerts, iframes, dynamic content  
- Exporting scraped data to Excel (`.xlsx`) using pandas  

---

##  About Me

Hi! Iâ€™m **[Janhvi Tiwari]**, an aspiring data automation developer.  
- ðŸ”­ Currently building and sharing web scraping projects  
- ðŸ“« Connect with me on [LinkedIn](https://www.linkedin.com/in/janhvi-tiwari-1bb152292/)  
- ðŸ’» Explore my other work: https://github.com/JANHVI15CMD 

---

##  Ethical Disclaimer

This project is for educational purposes only.  
Please respect each websiteâ€™s `robots.txt` and Terms of Service.
```